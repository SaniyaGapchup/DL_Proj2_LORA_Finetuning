# AGâ€‘News Classification with LoRAâ€‘fineâ€‘tuned RoBERTa



## ğŸ“– Introduction

This project demonstrates how to fineâ€‘tune [**RoBERTaâ€‘base**](https://arxiv.org/abs/1907.11692) for newsâ€‘topic classification on theâ€¯AGÂ News dataset **using Lowâ€‘Rank Adaptation (LoRA)**â€”all inside a single, selfâ€‘contained **Jupyter notebook (**``**)**.  LoRA inserts small rankâ€‘decomposition matrices into the attention projections, letting us adapt a large preâ€‘trained model with a **fraction of the parameters** and GPU memory normally required.

## ğŸ¯ Purpose of the Notebook

- Provide a **reproducible walkthrough** of LoRA for sequence classification usingÂ Transformers & PEFT.
- Log metrics, checkpoints, and the final merged model in one place.
- Empirically show why **rankÂ 4 / alphaÂ 4** strikes the best accuracyâ€“efficiency balance on a singleâ€‘GPU workstation.

## ğŸ—ï¸ Experimental Setup

| Component      | Value                                       |
| -------------- | ------------------------------------------- |
| Base model     | `roberta-base`                              |
| Dataset        | AGÂ News                                     |
| Adapter method | LoRA                                        |
| **Rank **``    | **4**                                       |
| **Alpha**      | **4**                                       |
| Dropout        | 0.2                                         |
| Optimizer      | **AdamW**                                   |
| Learning rate  | 1Â Ã—â€¯10â»âµ                                    |
| Batch size     | 16 (train) / 64 (eval)                      |
| Steps          | 2â€¯000                                       |
| Hardware       | NVIDIA **RTXÂ 4090** (24Â GB VRAM)            |

### Why **rÂ =Â 4, Î±Â =Â 4**?

Lower ranks (e.g.â€¯2) underâ€‘fit, while higher ranks (â‰¥â€¯8) yield only marginal accuracy gains at the cost of more parameters and longer runtime. Rankâ€¯4 provides the **best validation accuracy (\~â€¯89â€¯%)** with an adapter of \~0.8â€¯M parametersâ€”just 0.4â€¯% of full RoBERTaâ€‘base.

## ğŸ“‰ Loss Curves
                                                                                                                                                                                               
![Training & Validation Loss](./roberta_agnews_finetuned/loss_curves.png)

The plot above tracks training and validation loss over 2â€¯000 steps.  Validation loss consistently stays below training loss, signalling healthy generalisation and the regularising effect of LoRA.

## ğŸš€ GettingÂ Started

> **Prerequisite:** A CUDAâ€‘capable GPU (â‰ˆ8â€¯GB VRAM minimum;â€¯24â€¯GB for full batch sizes).  CPU execution works but will be slow.

```bash
# 1. Clone the repo and enter it
git clone https://github.com/SaniyaGapchup/DL_Proj2_LORA_Finetuning.git
cd robertaâ€‘agnewsâ€‘lora

# 2. Create an environment
conda create -n lora_roberta python=3.10
conda activate lora_roberta
pip install torch transformers peft datasets evaluate matplotlib scikit-learn pandas numpy jupyter

# 3. Launch Jupyter
jupyter lab  # or jupyter notebook
# Open DL_P2.ipynb and run the cells topâ€‘toâ€‘bottom
```

The notebook will:

1. Download AGÂ News and RoBERTaâ€‘base.
2. Configure LoRA (râ€¯=â€¯4, Î±â€¯=â€¯4).
3. Train for 2â€¯000 steps with AdamW.
4. Plot the loss curves and evaluate accuracy.
5. Save the adapter, merged model, and a CSV of predictions (if unlabelled data is provided).

## ğŸ“‚ Repository Contents

```
â”œâ”€â”€ DL_P2.ipynb              # main notebook (run this!)
â”œâ”€â”€ loss_curves.png          # training/validation loss plot
â”œâ”€â”€ roberta_agnews_finetuned/   # LoRA checkpoints & merged model
â”‚   â”œâ”€â”€ adapter_model.bin
â”‚   â””â”€â”€ ...
â””â”€â”€ README.md
```

## ğŸ“ Results

The notebook continues to keep **validation** and **test** data strictly separate:

* **Validation set**Â â€“Â 1â€¯280 examples *heldâ€‘out* from the original training split (stratified via `train_test_split`).  Used only for early stopping and hyperâ€‘parameter selection.
* **Test set**Â â€“Â **all 7â€¯600 rows** of the official AGÂ News test split.  Never seen during training or validation.

| Split | Size | Accuracy |
|-------|------|----------|
| Validation | 1â€¯280 | **â‰ˆâ€¯89â€¯%** |
| Test | 7â€¯600 | **â‰ˆâ€¯88â€¯%** |

Evaluating on the full test corpus confirms the model generalises well; scores fall in the 88-89â€¯% band depending on random seed.

## âœ¨ Acknowledgements

- **Hugging Face** community for datasets and tooling.
- **LoRA** (HuÂ *etÂ al.*,Â 2021) for parameterâ€‘efficient fineâ€‘tuning.

## ğŸ“œ License

Released under the MIT License. See `LICENSE` for details.

